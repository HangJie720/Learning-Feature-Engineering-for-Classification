{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, regularizers\n",
    "\n",
    "from sklearn import ensemble, preprocessing, multiclass\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transformation\n",
    "\n",
    "def sqrt(col):\n",
    "    return list(map(np.sqrt, col));\n",
    "\n",
    "def freq(col):\n",
    "    col = np.floor(col)\n",
    "    counter = Counter(col)\n",
    "    return [counter.get(elem) for elem in col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "\n",
    "# Datasets\n",
    "dids = np.load(\"datasets/indexes.npy\")\n",
    "\n",
    "# RF model parameters\n",
    "seed = 67\n",
    "transformations = [sqrt, freq]\n",
    "transformations_name = [\"sqrt\", \"freq\"]\n",
    "trans2target = {}\n",
    "\n",
    "# Comrpessed Dataset paramters\n",
    "qsa_representation = []\n",
    "num_bin = 20\n",
    "\n",
    "# Neural Nets Parameters and Variables\n",
    "MLP_LFE_Nets = {}\n",
    "inp_shape = (2,num_bin)\n",
    "dropout = 0.2\n",
    "norm = (-10, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def binarize_dataset():\n",
    "\n",
    "def load_dataset(id):\n",
    "    X = np.load(\"datasets/\" + str(id) + \"-data.npy\")\n",
    "    y = np.load(\"datasets/\" + str(id) + \"-target.npy\")\n",
    "    categorical = np.load(\"datasets/\" + str(id) + \"-categorical.npy\")\n",
    "    return X,y,categorical\n",
    "\n",
    "    \n",
    "def evaluate_model(X, y, categorical):\n",
    "    imp = Imputer(missing_values=\"NaN\")\n",
    "    X = imp.fit_transform(X)\n",
    "    enc = preprocessing.OneHotEncoder(categorical_features=categorical)\n",
    "    X = enc.fit_transform(X)\n",
    "    clf = ensemble.RandomForestClassifier(random_state=seed)\n",
    "    #clf_ovsr = multiclass.OneVsRestClassifier(clf, n_jobs=-1)\n",
    "    \n",
    "    return cross_val_score(clf, X, y,cv=10)\n",
    "    \n",
    "def is_positive(X,y,categorical,base_score,transformation,feature):\n",
    "    transformed_feature = np.array(transformation(X[:,feature]))\n",
    "    X = np.c_[X,transformed_feature]\n",
    "    categorical = np.append(categorical,False)\n",
    "    new_score = evaluate_model(X,y,categorical).mean()\n",
    "    \n",
    "    return 1 if(base_score <= (new_score - 0.01)) else 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start dataset number 4\n",
      "\tEvaluating feature 0\n",
      "\t\t1\n",
      "\tEvaluating feature 1\n",
      "\t\t0\n",
      "\tEvaluating feature 2\n",
      "\t\t1\n",
      "\tEvaluating feature 3\n",
      "\t\t1\n",
      "\tEvaluating feature 5\n",
      "\t\t1\n",
      "\tEvaluating feature 7\n",
      "\t\t1\n",
      "\tEvaluating feature 8\n",
      "\t\t1\n",
      "\tEvaluating feature 10\n",
      "\t\t1\n",
      "\tEvaluating feature 0\n",
      "\t\t1\n",
      "\tEvaluating feature 1\n",
      "\t\t1\n",
      "\tEvaluating feature 2\n",
      "\t\t1\n",
      "\tEvaluating feature 3\n",
      "\t\t1\n",
      "\tEvaluating feature 5\n",
      "\t\t0\n",
      "\tEvaluating feature 7\n",
      "\t\t1\n",
      "\tEvaluating feature 8\n",
      "\t\t1\n",
      "\tEvaluating feature 10\n",
      "\t\t1\n",
      "Start dataset number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEvaluating feature 0\n",
      "\t\t0\n",
      "\tEvaluating feature 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t0\n",
      "\tEvaluating feature 2\n",
      "\t\t0\n",
      "\tEvaluating feature 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t0\n",
      "\tEvaluating feature 4\n",
      "\t\t0\n",
      "\tEvaluating feature 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t0\n",
      "\tEvaluating feature 1\n",
      "\t\t1\n",
      "\tEvaluating feature 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t0\n",
      "\tEvaluating feature 3\n",
      "\t\t0\n",
      "\tEvaluating feature 4\n",
      "\t\t0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrea\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:597: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# Build the target for the compressed feature\n",
    "\n",
    "for transf in transformations:\n",
    "    trans2target[transf] = []\n",
    "\n",
    "for did in dids[:2]:\n",
    "    print(\"Start dataset number\", did)\n",
    "    \n",
    "    X, y, categorical = load_dataset(did)\n",
    "    \n",
    "    base_score = evaluate_model(X, y, categorical).mean()\n",
    "    \n",
    "    # Find the indexes of numeric attributes\n",
    "    numerical_indexes = np.where(np.invert(categorical))[0]\n",
    "    \n",
    "    for i,transf in enumerate(transformations):\n",
    "        for feature in numerical_indexes:\n",
    "            \n",
    "            print(\"\\tEvaluating feature \" + str(feature))\n",
    "            \n",
    "            mlp_target = is_positive(X,y,categorical,base_score,transf, feature)\n",
    "            \n",
    "            print(\"\\t\\t\" + str(mlp_target))\n",
    "            \n",
    "            trans2target[transf].append((did,feature,mlp_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the result\n",
    "\n",
    "for transf, name in zip(transformations, transformations_name):\n",
    "    np.save(\"datasets/transformation_ds/\" + name, trans2target[transf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_Rx(matrix):\n",
    "    \n",
    "    Rxc = np.zeros(shape=matrix.shape)\n",
    "    \n",
    "    for i,row in enumerate(matrix):\n",
    "        max_c = np.amax(row)\n",
    "        min_c = np.amin(row)\n",
    "        bin_width = (max_c-min_c)/(norm[1]-norm[0])\n",
    "        Rxc[i] = np.apply_along_axis(lambda x : np.floor((x-min_c)/(bin_width)+norm[0]), 0, row)\n",
    "    \n",
    "    return Rxc\n",
    "\n",
    "def to_quantile_sketch_array(did, col, targets, bins, t_class, index):\n",
    "    max_c = np.nanmax(col)\n",
    "    min_c = np.nanmin(col)\n",
    "    bin_width = (max_c-min_c)/num_bin\n",
    "    Rx = np.zeros(shape=(2,num_bin))\n",
    "    \n",
    "    for val,y in zip(col,targets):\n",
    "        if not np.isnan(val):\n",
    "            bin_value = int(np.floor((val-min_c)/bin_width))\n",
    "            bin_value = np.clip(bin_value, 0, num_bin-1)\n",
    "            my_class = 0 if t_class == y else 1\n",
    "            Rx[my_class][bin_value] = Rx[my_class][bin_value] + 1\n",
    "            \n",
    "    Rx = normalize_Rx(Rx)\n",
    "\n",
    "    qsa_representation.append(np.insert(Rx.flatten(), 0, [did,index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start dataset number 4\n"
     ]
    }
   ],
   "source": [
    "# Build the compressed dataset\n",
    "\n",
    "for did in dids[:1]:\n",
    "    print(\"Start dataset number\", did)\n",
    "    \n",
    "    X, y, categorical = load_dataset(did)\n",
    "    numerical_indexes = np.where(np.invert(categorical))[0]\n",
    "    \n",
    "    classes = set(y)\n",
    "\n",
    "    for t_class in classes:\n",
    "        for index in numerical_indexes:\n",
    "            to_quantile_sketch_array(did,X[:,index], y, num_bin, t_class, index)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.,   0.,   0., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  10., -10., -10., -10., -10., -10., -10., -10., -10.,   0.,\n",
       "         -5., -10., -10., -10., -10., -10., -10., -10., -10., -10.,  10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10.,   6.],\n",
       "       [  4.,   1.,  10., -10.,  -2.,  -8.,  -8., -10.,  -8., -10.,  -4.,\n",
       "        -10.,  -8., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "         -6., -10., -10.,  -8.,  -4., -10.,   1., -10.,  -4.,  -8.,  10.,\n",
       "        -10.,   1., -10.,  -6., -10.,  -6.,  -8., -10.,  -6.],\n",
       "       [  4.,   2.,   2., -10.,  10., -10.,   2., -10., -10., -10.,   2.,\n",
       "        -10., -10., -10.,  -6., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10.,  -8., -10.,  -6., -10.,  -8., -10.,  10.,  -6.,   2.,\n",
       "         -8.,  -4.,  -8., -10.,  -8.,  -8.,  -8., -10.,  -8.],\n",
       "       [  4.,   3.,  10., -10., -10.,  -4., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  -7., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  -7., -10., -10., -10.,   0., -10., -10.,  10.],\n",
       "       [  4.,   5., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10.,  -9., -10., -10.,  -9.,  -4., -10.,  -9.,  10.,\n",
       "         -9., -10., -10., -10., -10., -10., -10., -10., -10.,  -9., -10.,\n",
       "        -10.,   0.,  -7., -10.,  -5.,   4., -10., -10.,  10.],\n",
       "       [  4.,   7.,  10., -10., -10.,  -4., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,  10.,\n",
       "        -10., -10.,  10., -10., -10.,  10., -10.,  10.,  10.],\n",
       "       [  4.,   8.,   0.,   0.,  10., -10.,  -5., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  -5.,  -3.,   5.,  10., -10., -10., -10.,  -8., -10., -10.,\n",
       "         -8., -10., -10., -10., -10., -10., -10., -10.,  -8.],\n",
       "       [  4.,  10.,  -6., -10., -10.,  10., -10., -10.,   2., -10., -10.,\n",
       "        -10.,  -6., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "         -8., -10., -10.,  -8., -10., -10.,  10., -10., -10., -10.,   2.,\n",
       "        -10., -10.,  -6., -10., -10., -10., -10., -10.,  -8.],\n",
       "       [  4.,   0.,  -5., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  10., -10., -10., -10., -10., -10., -10., -10., -10.,   6.,\n",
       "          0., -10., -10., -10., -10., -10., -10., -10., -10., -10.,  10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10.,   0.],\n",
       "       [  4.,   1.,  -6., -10., -10.,  -8.,  -4., -10.,   1., -10.,  -4.,\n",
       "         -8.,  10., -10.,   1., -10.,  -6., -10.,  -6.,  -8., -10.,  -6.,\n",
       "         10., -10.,  -2.,  -8.,  -8., -10.,  -8., -10.,  -4., -10.,  -8.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "       [  4.,   2., -10., -10.,  -8., -10.,  -6., -10.,  -8., -10.,  10.,\n",
       "         -6.,   2.,  -8.,  -4.,  -8., -10.,  -8.,  -8.,  -8., -10.,  -8.,\n",
       "          2., -10.,  10., -10.,   2., -10., -10., -10.,   2., -10., -10.,\n",
       "        -10.,  -6., -10., -10., -10., -10., -10., -10., -10.],\n",
       "       [  4.,   3., -10.,  -7., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10.,  -7., -10., -10., -10.,   0., -10., -10.,  10.,\n",
       "         10., -10., -10.,  -4., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "       [  4.,   5.,  -9., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "         -9., -10., -10.,   0.,  -7., -10.,  -5.,   4., -10., -10.,  10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  -9., -10., -10.,  -9.,  -4., -10.,  -9.,  10.],\n",
       "       [  4.,   7., -10., -10., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10.,  10., -10., -10.,  10., -10., -10.,  10., -10.,  10.,  10.,\n",
       "         10., -10., -10.,  -4., -10., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "       [  4.,   8., -10.,  -5.,  -3.,   5.,  10., -10., -10., -10.,  -8.,\n",
       "        -10., -10.,  -8., -10., -10., -10., -10., -10., -10., -10.,  -8.,\n",
       "          0.,   0.,  10., -10.,  -5., -10., -10., -10., -10., -10., -10.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10.],\n",
       "       [  4.,  10.,  -8., -10., -10.,  -8., -10., -10.,  10., -10., -10.,\n",
       "        -10.,   2., -10., -10.,  -6., -10., -10., -10., -10., -10.,  -8.,\n",
       "         -6., -10., -10.,  10., -10., -10.,   2., -10., -10., -10.,  -6.,\n",
       "        -10., -10., -10., -10., -10., -10., -10., -10., -10.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the compressed datasets\n",
    "np.save(\"datasets/compressed/compressed.npy\", qsa_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_targets():\n",
    "    return []\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CREATING THE NEURAL NETS\n",
    "\n",
    "for transf in transformations_name:\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(64, input_shape=inp_shape, W_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.add(Dense(64, W_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # For a binary classification problem\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    MLP_LFE_Nets[transf] = model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training the nets\n",
    "\n",
    "\n",
    "for transf, name in zip(transformations, transformations_name):\n",
    "    k = np.load(\"datasets/transformation_ds/\" + name + \".npy\")\n",
    "    print(k)\n",
    "\n",
    "for id in dids[:100]:\n",
    "    targets = load_targets(\"datasets/targets.npy\")\n",
    "    X = load_only_numeric_data(id)\n",
    "    \n",
    "    for i,trans in enumerate(transformations):\n",
    "        for feature, target in zip(X.transpose(), targets):\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
